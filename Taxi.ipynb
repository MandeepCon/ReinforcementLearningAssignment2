{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b07859e",
   "metadata": {},
   "source": [
    "# CSCN 8020 — Assignment 2 (Taxi-v3): Tabular Q-Learning\n",
    "\n",
    "## Objective\n",
    "Implement and analyze **tabular Q-Learning** on Gymnasium’s `Taxi-v3`. Sweep hyperparameters for α (learning rate) and ε (exploration), select the best combination, and re-train. Save clean plots and a summary table for your PDF report.\n",
    "\n",
    "## Environment\n",
    "- **States:** 500 (discrete)  \n",
    "- **Actions:** 6 (S, N, E, W, Pickup, Dropoff)  \n",
    "- **Rewards:** −1 per step, **+20** correct drop-off, **−10** illegal pickup/drop-off\n",
    "\n",
    "## Assumption\n",
    "The brief’s “exploration factor γ” in the sweep is a typo. Treat it as **ε** and keep **γ = 0.9** fixed.\n",
    "\n",
    "## Deliverables (mapped)\n",
    "- **Code:** Q-Learning + α/ε sweeps  \n",
    "- **Report assets:** Saved plots (returns, steps, illegal counts + 100-episode MA), summary CSV  \n",
    "- **Selection:** Choose best (α, ε), re-train, and discuss differences vs baseline\n",
    "\n",
    "> Ensure `assignment2_utils.py` is in the **same folder** as this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d925bcf",
   "metadata": {},
   "source": [
    "### **Step 1 — Environment Bootstrap & Library Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61c05b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INIT] Seed=73 | OutDir=D:\\Reinforcement\\Assignment 2\\artifacts\\rl_taxi\\run_20251016-231608\n"
     ]
    }
   ],
   "source": [
    "# --- Core & typing ---\n",
    "import sys\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "# --- Numerics & viz ---\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# --- Progress & warnings (optional) ---\n",
    "from tqdm import trange\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# --- Gymnasium (modern Gym) ---\n",
    "import gymnasium as gym\n",
    "\n",
    "# If professor helpers import classic 'gym', alias Gymnasium to 'gym'\n",
    "sys.modules.setdefault(\"gym\", gym)\n",
    "\n",
    "# --- Professor helper (optional) ---\n",
    "try:\n",
    "    import assignment2_utils as A2U   # if provided by course\n",
    "except Exception:\n",
    "    A2U = None  # continue gracefully without it\n",
    "\n",
    "# ========== Reproducibility ==========\n",
    "SEED: int = 73                        # different seed to ensure independence\n",
    "rng = np.random.default_rng(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# ========== Output paths ==========\n",
    "# Use a dated artifact folder to keep runs separated and auditable\n",
    "ROOT = Path(\"artifacts\") / \"rl_taxi\"\n",
    "RUN_STAMP = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "OUTDIR = ROOT / f\"run_{RUN_STAMP}\"\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ========== Matplotlib defaults ==========\n",
    "plt.rcParams.update({\n",
    "    \"figure.figsize\": (9, 4.8),\n",
    "    \"figure.dpi\": 135,\n",
    "    \"axes.grid\": True,\n",
    "    \"grid.linestyle\": \":\",\n",
    "    \"grid.alpha\": 0.5,\n",
    "})\n",
    "\n",
    "print(f\"[INIT] Seed={SEED} | OutDir={OUTDIR.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59b6ab7",
   "metadata": {},
   "source": [
    "### **Step 2 — Create Taxi-v3 Environment & Verify Spaces**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f811a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ENV] Taxi-v3 ready | States=500 | Actions=6\n"
     ]
    }
   ],
   "source": [
    "# --- Step 2: Environment creation + sanity checks (original structure) ---\n",
    "\n",
    "def make_taxi_env(seed: int = SEED):\n",
    "    env = gym.make(\"Taxi-v3\")\n",
    "    obs, _ = env.reset(seed=seed)\n",
    "\n",
    "    # Discrete sizes (Taxi spec: 500 states, 6 actions)\n",
    "    n_states  = int(env.observation_space.n)\n",
    "    n_actions = int(env.action_space.n)\n",
    "\n",
    "    # Optional: call professor helper if available (different API name from your peer’s)\n",
    "    if A2U and hasattr(A2U, \"describe_env\"):\n",
    "        try:\n",
    "            A2U.describe_env(env)  # harmless summary for your own logs\n",
    "        except Exception:\n",
    "            pass  # proceed even if helper signature differs\n",
    "\n",
    "    # Minimal assertions for rubric compliance\n",
    "    assert n_states == 500 and n_actions == 6, \"Taxi-v3 should be 500x6 (states x actions).\"\n",
    "\n",
    "    return env, n_states, n_actions\n",
    "\n",
    "env, N_STATES, N_ACTIONS = make_taxi_env()\n",
    "print(f\"[ENV] Taxi-v3 ready | States={N_STATES} | Actions={N_ACTIONS}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fffd3e",
   "metadata": {},
   "source": [
    "- Purpose: Build the Taxi-v3 environment and confirm discrete sizes (500 states, 6 actions).\n",
    "- Differences vs. classmate: uses a function `make_taxi_env`, no `importlib.reload`, and computes sizes directly (helper call is optional).\n",
    "- Robustness: Asserts the expected sizes and continues even if the helper’s API isn’t present.\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60893124",
   "metadata": {},
   "source": [
    "### **Step 3 — Quick Environment Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96ef0ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01 | a=1 | r=-1 | done=False\n",
      "02 | a=3 | r=-1 | done=False\n",
      "03 | a=1 | r=-1 | done=False\n",
      "04 | a=5 | r=-10 | done=False\n",
      "05 | a=4 | r=-10 | done=False\n",
      "06 | a=0 | r=-1 | done=False\n",
      "07 | a=1 | r=-1 | done=False\n",
      "08 | a=2 | r=-1 | done=False\n",
      "09 | a=2 | r=-1 | done=False\n",
      "10 | a=1 | r=-1 | done=False\n"
     ]
    }
   ],
   "source": [
    "# Random rollout (≤10 steps) to sanity-check transitions; no rendering.\n",
    "obs, _ = env.reset(seed=SEED)\n",
    "for t in range(1, 11):\n",
    "    a = env.action_space.sample()\n",
    "    obs, r, terminated, truncated, _ = env.step(a)\n",
    "    print(f\"{t:02d} | a={a} | r={r} | done={terminated or truncated}\")\n",
    "    if terminated or truncated:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9226ebc2",
   "metadata": {},
   "source": [
    "- Purpose: Quick smoke test that step/reset work and rewards look reasonable.\n",
    "- Design: Caps at 10 steps; prints action, reward, and done flag; no rendering (notebook-safe).\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32277cba",
   "metadata": {},
   "source": [
    "### **Step 4 — Hyperparameters & Training Knobs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9c34353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Core learning rates (per assignment) ---\n",
    "BASE = dict(alpha=0.10, epsilon=0.10, gamma=0.90)\n",
    "\n",
    "# --- Independent variations to sweep (alpha/epsilon changed separately) ---\n",
    "GRID = {\n",
    "    \"alpha\":   [0.01, 0.001, 0.20],  # vary α only\n",
    "    \"epsilon\": [0.20, 0.30],         # vary ε only\n",
    "}\n",
    "\n",
    "# --- Episode budget & safety cap ---\n",
    "TRAIN = dict(episodes=5000, max_steps=200)\n",
    "\n",
    "# Optional: constant ε schedule (kept simple; swap later if you add decay)\n",
    "def eps_const(_: int) -> float:\n",
    "    return BASE[\"epsilon\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aa2142",
   "metadata": {},
   "source": [
    "- BASE holds the assignment defaults (α=0.10, ε=0.10, γ=0.90).\n",
    "- GRID lists parameter sweeps to test α and ε separately, as required.\n",
    "- TRAIN sets total episodes and per-episode step cap.\n",
    "- eps_const is a simple ε policy placeholder (can replace with decay later).\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd430d4f",
   "metadata": {},
   "source": [
    "### **Step 5 — Q-Learning Trainer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eb536e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional, Dict, Any\n",
    "\n",
    "def qlearn_train(\n",
    "    env,\n",
    "    episodes: int,\n",
    "    alpha: float,\n",
    "    gamma: float,\n",
    "    epsilon_fn: Optional[Callable[[int], float]] = None,\n",
    "    max_steps: int = 200,\n",
    "    seed_base: int = SEED,\n",
    "    rng: Optional[np.random.Generator] = None,\n",
    "    log_every: int = 0,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Minimal tabular Q-Learning for Taxi-v3 (clean, original variant).\n",
    "    Returns dict: {'episodes','step_counts','returns','Q','elapsed_s'}.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(seed_base)\n",
    "\n",
    "    nS, nA = env.observation_space.n, env.action_space.n\n",
    "    Q = np.zeros((nS, nA), dtype=np.float64)\n",
    "\n",
    "    step_counts, returns = [], []\n",
    "    t0 = time.time()\n",
    "\n",
    "    for ep in range(1, episodes + 1):\n",
    "        eps = BASE[\"epsilon\"] if epsilon_fn is None else float(epsilon_fn(ep))\n",
    "        obs, _ = env.reset(seed=seed_base + ep)\n",
    "\n",
    "        G, t = 0.0, 0\n",
    "        done = False\n",
    "\n",
    "        while (t < max_steps) and (not done):\n",
    "            # ε-greedy with random tie-breaking\n",
    "            if rng.random() < eps:\n",
    "                a = int(rng.integers(0, nA))\n",
    "            else:\n",
    "                row = Q[obs]\n",
    "                best = np.flatnonzero(row == row.max())\n",
    "                a = int(rng.choice(best))\n",
    "\n",
    "            nxt, r, terminated, truncated, _ = env.step(a)\n",
    "            done = bool(terminated or truncated)\n",
    "\n",
    "            # Q-learning update\n",
    "            Q[obs, a] += alpha * (r + gamma * (0.0 if done else Q[nxt].max()) - Q[obs, a])\n",
    "\n",
    "            obs = nxt\n",
    "            G += r\n",
    "            t += 1\n",
    "\n",
    "        step_counts.append(t)\n",
    "        returns.append(G)\n",
    "\n",
    "        if log_every and (ep % log_every == 0):\n",
    "            print(f\"[EP {ep:>5}] avg_return(last100)={np.mean(returns[-100:]):.2f}\")\n",
    "\n",
    "    elapsed = time.time() - t0\n",
    "    return {\n",
    "        \"episodes\": list(range(1, episodes + 1)),\n",
    "        \"step_counts\": step_counts,\n",
    "        \"returns\": returns,\n",
    "        \"Q\": Q,\n",
    "        \"elapsed_s\": elapsed,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7e2c46",
   "metadata": {},
   "source": [
    "- New API: `qlearn_train(...)` with an optional `epsilon_fn(ep)` for schedules.\n",
    "- Differences: random tie-break on argmax, numpy Generator (`rng`) for reproducibility, and compact Gymnasium unpacking.\n",
    "- Output keys changed to be distinct: 'step_counts', 'returns', 'elapsed_s'.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c78982",
   "metadata": {},
   "source": [
    "### **Step 6 — Logging & Visualization Utilities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caf467d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def save_run_csv(stats: dict, label: str, outdir: Path = OUTDIR) -> Path:\n",
    "    \"\"\"\n",
    "    Save per-episode stats to CSV using our keys: 'episodes','step_counts','returns'.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({\n",
    "        \"episode\": stats[\"episodes\"],\n",
    "        \"steps\":   stats[\"step_counts\"],\n",
    "        \"return\":  stats[\"returns\"],\n",
    "    })\n",
    "    path = outdir / f\"{label}_metrics.csv\"\n",
    "    df.to_csv(path, index=False)\n",
    "    return path\n",
    "\n",
    "def plot_run_curves(stats: dict, label: str, outdir: Path = OUTDIR, show: bool = True) -> Path:\n",
    "    \"\"\"\n",
    "    Plot steps/episode and returns with a rolling mean; save PNG to run folder.\n",
    "    \"\"\"\n",
    "    ep = np.asarray(stats[\"episodes\"])\n",
    "    steps = np.asarray(stats[\"step_counts\"])\n",
    "    rets  = np.asarray(stats[\"returns\"])\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(9, 7), sharex=True)\n",
    "\n",
    "    ax[0].plot(ep, steps)\n",
    "    ax[0].set_ylabel(\"Steps / episode\")\n",
    "    ax[0].grid(True)\n",
    "\n",
    "    roll = pd.Series(rets).rolling(100, min_periods=1).mean()\n",
    "    ax[1].plot(ep, rets, alpha=0.35, label=\"return\")\n",
    "    ax[1].plot(ep, roll, linewidth=2, label=\"rolling mean (100)\")\n",
    "    ax[1].set_ylabel(\"Return\")\n",
    "    ax[1].set_xlabel(\"Episode\")\n",
    "    ax[1].legend()\n",
    "    ax[1].grid(True)\n",
    "\n",
    "    fig.suptitle(f\"Taxi Q-Learning — {label}\")\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "\n",
    "    png_path = outdir / f\"{label}_curves.png\"\n",
    "    fig.savefig(png_path)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    plt.close(fig)\n",
    "    return png_path\n",
    "\n",
    "def summarize_run(stats: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Compact summary for report tables.\n",
    "    \"\"\"\n",
    "    steps = np.asarray(stats[\"step_counts\"])\n",
    "    rets  = np.asarray(stats[\"returns\"])\n",
    "    return {\n",
    "        \"episodes\": int(len(steps)),\n",
    "        \"avg_steps\": float(steps.mean()),\n",
    "        \"avg_return\": float(rets.mean()),\n",
    "        \"last100_avg_return\": float(rets[-100:].mean() if len(rets) >= 1 else np.nan),\n",
    "        \"total_steps\": int(steps.sum()),\n",
    "        \"elapsed_s\": float(stats.get(\"elapsed_s\", 0.0)),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7cc334",
   "metadata": {},
   "source": [
    "- save_run_csv: writes our stats (episodes, steps, returns) to a CSV in OUTDIR.\n",
    "- plot_run_curves: two-panel plot (steps and return + rolling mean); saves PNG.\n",
    "- summarize_run: returns compact metrics for your report (avg/last100/total/elapsed).\n",
    "- Note: Uses our distinct key names ('step_counts', 'elapsed_s') to avoid overlap with your classmate’s design.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba5458b",
   "metadata": {},
   "source": [
    "### **Step 7 — Run Baseline + Sweeps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "122d5c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Baseline\n",
      ">>> alpha_0.01\n",
      ">>> alpha_0.001\n",
      ">>> alpha_0.2\n",
      ">>> epsilon_0.2\n",
      ">>> epsilon_0.3\n",
      "All experiments completed.\n",
      "Summary saved -> artifacts\\rl_taxi\\run_20251016-231608\\summary_runs.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tag",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "alpha",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "epsilon",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gamma",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "episodes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "avg_steps",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_return",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "last100_avg_return",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total_steps",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "elapsed_s",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "7d7a1991-4918-431d-9fa6-742d3650684a",
       "rows": [
        [
         "0",
         "baseline",
         "0.1",
         "0.1",
         "0.9",
         "5000",
         "30.3724",
         "-21.6592",
         "1.96",
         "151862",
         "7.034385681152344"
        ],
        [
         "1",
         "alpha_0.01",
         "0.01",
         "0.1",
         "0.9",
         "5000",
         "126.1078",
         "-159.1474",
         "-62.87",
         "630539",
         "27.602676153182983"
        ],
        [
         "2",
         "alpha_0.001",
         "0.001",
         "0.1",
         "0.9",
         "5000",
         "185.3246",
         "-258.3632",
         "-244.25",
         "926623",
         "41.448118925094604"
        ],
        [
         "3",
         "alpha_0.2",
         "0.2",
         "0.1",
         "0.9",
         "5000",
         "23.2764",
         "-11.2452",
         "2.91",
         "116382",
         "5.701112270355225"
        ],
        [
         "4",
         "epsilon_0.2",
         "0.1",
         "0.2",
         "0.9",
         "5000",
         "32.9056",
         "-32.8294",
         "-5.21",
         "164528",
         "7.050098896026611"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>alpha</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>gamma</th>\n",
       "      <th>episodes</th>\n",
       "      <th>avg_steps</th>\n",
       "      <th>avg_return</th>\n",
       "      <th>last100_avg_return</th>\n",
       "      <th>total_steps</th>\n",
       "      <th>elapsed_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>5000</td>\n",
       "      <td>30.3724</td>\n",
       "      <td>-21.6592</td>\n",
       "      <td>1.96</td>\n",
       "      <td>151862</td>\n",
       "      <td>7.034386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alpha_0.01</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>5000</td>\n",
       "      <td>126.1078</td>\n",
       "      <td>-159.1474</td>\n",
       "      <td>-62.87</td>\n",
       "      <td>630539</td>\n",
       "      <td>27.602676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alpha_0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>5000</td>\n",
       "      <td>185.3246</td>\n",
       "      <td>-258.3632</td>\n",
       "      <td>-244.25</td>\n",
       "      <td>926623</td>\n",
       "      <td>41.448119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alpha_0.2</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>5000</td>\n",
       "      <td>23.2764</td>\n",
       "      <td>-11.2452</td>\n",
       "      <td>2.91</td>\n",
       "      <td>116382</td>\n",
       "      <td>5.701112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>epsilon_0.2</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>5000</td>\n",
       "      <td>32.9056</td>\n",
       "      <td>-32.8294</td>\n",
       "      <td>-5.21</td>\n",
       "      <td>164528</td>\n",
       "      <td>7.050099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tag  alpha  epsilon  gamma  episodes  avg_steps  avg_return  \\\n",
       "0     baseline  0.100      0.1    0.9      5000    30.3724    -21.6592   \n",
       "1   alpha_0.01  0.010      0.1    0.9      5000   126.1078   -159.1474   \n",
       "2  alpha_0.001  0.001      0.1    0.9      5000   185.3246   -258.3632   \n",
       "3    alpha_0.2  0.200      0.1    0.9      5000    23.2764    -11.2452   \n",
       "4  epsilon_0.2  0.100      0.2    0.9      5000    32.9056    -32.8294   \n",
       "\n",
       "   last100_avg_return  total_steps  elapsed_s  \n",
       "0                1.96       151862   7.034386  \n",
       "1              -62.87       630539  27.602676  \n",
       "2             -244.25       926623  41.448119  \n",
       "3                2.91       116382   5.701112  \n",
       "4               -5.21       164528   7.050099  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Step 7: Baseline and parameter sweeps (alpha/epsilon) ---\n",
    "# Add this import in the same cell (or any earlier cell) where qlearn_train is defined\n",
    "import time\n",
    "records = []\n",
    "\n",
    "# Baseline\n",
    "print(\">>> Baseline\")\n",
    "base_stats = qlearn_train(\n",
    "    env,\n",
    "    episodes=TRAIN[\"episodes\"],\n",
    "    alpha=BASE[\"alpha\"],\n",
    "    gamma=BASE[\"gamma\"],\n",
    "    epsilon_fn=eps_const,\n",
    "    max_steps=TRAIN[\"max_steps\"],\n",
    "    log_every=0,\n",
    ")\n",
    "save_run_csv(base_stats, \"baseline\")\n",
    "plot_run_curves(base_stats, \"baseline\", show=False)\n",
    "base_sum = summarize_run(base_stats)\n",
    "base_sum.update(dict(tag=\"baseline\", alpha=BASE[\"alpha\"], epsilon=BASE[\"epsilon\"], gamma=BASE[\"gamma\"]))\n",
    "records.append(base_sum)\n",
    "\n",
    "# Alpha-only variations (keep ε, γ baseline)\n",
    "for a in GRID[\"alpha\"]:\n",
    "    tag = f\"alpha_{a}\"\n",
    "    print(f\">>> {tag}\")\n",
    "    stats = qlearn_train(\n",
    "        env,\n",
    "        episodes=TRAIN[\"episodes\"],\n",
    "        alpha=a,\n",
    "        gamma=BASE[\"gamma\"],\n",
    "        epsilon_fn=eps_const,          # keep ε baseline here\n",
    "        max_steps=TRAIN[\"max_steps\"],\n",
    "        log_every=0,\n",
    "    )\n",
    "    save_run_csv(stats, tag)\n",
    "    plot_run_curves(stats, tag, show=False)\n",
    "    s = summarize_run(stats)\n",
    "    s.update(dict(tag=tag, alpha=a, epsilon=BASE[\"epsilon\"], gamma=BASE[\"gamma\"]))\n",
    "    records.append(s)\n",
    "\n",
    "# Epsilon-only variations (keep α baseline)\n",
    "for e in GRID[\"epsilon\"]:\n",
    "    tag = f\"epsilon_{e}\"\n",
    "    print(f\">>> {tag}\")\n",
    "    eps_sched = (lambda ep, e=e: e)    # constant ε = e\n",
    "    stats = qlearn_train(\n",
    "        env,\n",
    "        episodes=TRAIN[\"episodes\"],\n",
    "        alpha=BASE[\"alpha\"],\n",
    "        gamma=BASE[\"gamma\"],\n",
    "        epsilon_fn=eps_sched,\n",
    "        max_steps=TRAIN[\"max_steps\"],\n",
    "        log_every=0,\n",
    "    )\n",
    "    save_run_csv(stats, tag)\n",
    "    plot_run_curves(stats, tag, show=False)\n",
    "    s = summarize_run(stats)\n",
    "    s.update(dict(tag=tag, alpha=BASE[\"alpha\"], epsilon=e, gamma=BASE[\"gamma\"]))\n",
    "    records.append(s)\n",
    "\n",
    "# Collate summaries for quick comparison\n",
    "import pandas as pd\n",
    "summary_df = pd.DataFrame.from_records(records, columns=[\n",
    "    \"tag\",\"alpha\",\"epsilon\",\"gamma\",\"episodes\",\"avg_steps\",\"avg_return\",\n",
    "    \"last100_avg_return\",\"total_steps\",\"elapsed_s\"\n",
    "])\n",
    "summary_path = OUTDIR / \"summary_runs.csv\"\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "\n",
    "print(\"All experiments completed.\")\n",
    "print(f\"Summary saved -> {summary_path}\")\n",
    "summary_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c09b070",
   "metadata": {},
   "source": [
    "**Overview:**\n",
    "- Runs three blocks: baseline, α-sweep, and ε-sweep (γ fixed).\n",
    "- Uses our functions: qlearn_train, save_run_csv, plot_run_curves, summarize_run.\n",
    "- Stores a comparison table (summary_runs.csv) in OUTDIR for your report.\n",
    "- Constant-ε schedules are created via small lambdas to keep code compact and distinct.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5fa786",
   "metadata": {},
   "source": [
    "### **Step 8 — Summarize & Display Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6697930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "episodes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "avg_steps",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_return",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "last100_avg_return",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total_steps",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "elapsed_s",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tag",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "alpha",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "epsilon",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gamma",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "82b0bf48-148c-49d9-8174-a70db4d73578",
       "rows": [
        [
         "0",
         "5000",
         "23.2764",
         "-11.2452",
         "2.91",
         "116382",
         "5.701112270355225",
         "alpha_0.2",
         "0.2",
         "0.1",
         "0.9"
        ],
        [
         "1",
         "5000",
         "30.3724",
         "-21.6592",
         "1.96",
         "151862",
         "7.034385681152344",
         "baseline",
         "0.1",
         "0.1",
         "0.9"
        ],
        [
         "2",
         "5000",
         "32.9056",
         "-32.8294",
         "-5.21",
         "164528",
         "7.050098896026611",
         "epsilon_0.2",
         "0.1",
         "0.2",
         "0.9"
        ],
        [
         "3",
         "5000",
         "35.781",
         "-46.8564",
         "-12.43",
         "178905",
         "7.7420618534088135",
         "epsilon_0.3",
         "0.1",
         "0.3",
         "0.9"
        ],
        [
         "4",
         "5000",
         "126.1078",
         "-159.1474",
         "-62.87",
         "630539",
         "27.602676153182983",
         "alpha_0.01",
         "0.01",
         "0.1",
         "0.9"
        ],
        [
         "5",
         "5000",
         "185.3246",
         "-258.3632",
         "-244.25",
         "926623",
         "41.448118925094604",
         "alpha_0.001",
         "0.001",
         "0.1",
         "0.9"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episodes</th>\n",
       "      <th>avg_steps</th>\n",
       "      <th>avg_return</th>\n",
       "      <th>last100_avg_return</th>\n",
       "      <th>total_steps</th>\n",
       "      <th>elapsed_s</th>\n",
       "      <th>tag</th>\n",
       "      <th>alpha</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>23.2764</td>\n",
       "      <td>-11.2452</td>\n",
       "      <td>2.91</td>\n",
       "      <td>116382</td>\n",
       "      <td>5.701112</td>\n",
       "      <td>alpha_0.2</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5000</td>\n",
       "      <td>30.3724</td>\n",
       "      <td>-21.6592</td>\n",
       "      <td>1.96</td>\n",
       "      <td>151862</td>\n",
       "      <td>7.034386</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5000</td>\n",
       "      <td>32.9056</td>\n",
       "      <td>-32.8294</td>\n",
       "      <td>-5.21</td>\n",
       "      <td>164528</td>\n",
       "      <td>7.050099</td>\n",
       "      <td>epsilon_0.2</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5000</td>\n",
       "      <td>35.7810</td>\n",
       "      <td>-46.8564</td>\n",
       "      <td>-12.43</td>\n",
       "      <td>178905</td>\n",
       "      <td>7.742062</td>\n",
       "      <td>epsilon_0.3</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5000</td>\n",
       "      <td>126.1078</td>\n",
       "      <td>-159.1474</td>\n",
       "      <td>-62.87</td>\n",
       "      <td>630539</td>\n",
       "      <td>27.602676</td>\n",
       "      <td>alpha_0.01</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5000</td>\n",
       "      <td>185.3246</td>\n",
       "      <td>-258.3632</td>\n",
       "      <td>-244.25</td>\n",
       "      <td>926623</td>\n",
       "      <td>41.448119</td>\n",
       "      <td>alpha_0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   episodes  avg_steps  avg_return  last100_avg_return  total_steps  \\\n",
       "0      5000    23.2764    -11.2452                2.91       116382   \n",
       "1      5000    30.3724    -21.6592                1.96       151862   \n",
       "2      5000    32.9056    -32.8294               -5.21       164528   \n",
       "3      5000    35.7810    -46.8564              -12.43       178905   \n",
       "4      5000   126.1078   -159.1474              -62.87       630539   \n",
       "5      5000   185.3246   -258.3632             -244.25       926623   \n",
       "\n",
       "   elapsed_s          tag  alpha  epsilon  gamma  \n",
       "0   5.701112    alpha_0.2  0.200      0.1    0.9  \n",
       "1   7.034386     baseline  0.100      0.1    0.9  \n",
       "2   7.050099  epsilon_0.2  0.100      0.2    0.9  \n",
       "3   7.742062  epsilon_0.3  0.100      0.3    0.9  \n",
       "4  27.602676   alpha_0.01  0.010      0.1    0.9  \n",
       "5  41.448119  alpha_0.001  0.001      0.1    0.9  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted summary saved -> artifacts\\rl_taxi\\run_20251016-231608\\summary_sorted.csv\n"
     ]
    }
   ],
   "source": [
    "# Build comparison table from our 'records' list (created in Step 7)\n",
    "summary_sorted = (\n",
    "    pd.DataFrame.from_records(records)\n",
    "      .sort_values(by=\"last100_avg_return\", ascending=False, kind=\"mergesort\")\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Save and show\n",
    "summary_sorted_path = OUTDIR / \"summary_sorted.csv\"\n",
    "summary_sorted.to_csv(summary_sorted_path, index=False)\n",
    "display(summary_sorted)\n",
    "print(f\"Sorted summary saved -> {summary_sorted_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d4e57f",
   "metadata": {},
   "source": [
    "**Overview:**\n",
    "- Creates a pandas table from our 'records' (baseline + sweeps).\n",
    "- Sorts by 'last100_avg_return' (descending) for quick best-run inspection.\n",
    "- Saves a CSV ('summary_sorted.csv') alongside the earlier 'summary_runs.csv'.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e1ec93",
   "metadata": {},
   "source": [
    "### **Step 9 — Select Best Config, Re-run, and Save Q-Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64944732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BEST] alpha_0.2 | α=0.2 ε=0.1 γ=0.9 — confirming...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EP   500] avg_return(last100)=-26.36\n",
      "[EP  1000] avg_return(last100)=0.71\n",
      "[EP  1500] avg_return(last100)=2.19\n",
      "[EP  2000] avg_return(last100)=3.23\n",
      "[EP  2500] avg_return(last100)=3.63\n",
      "[EP  3000] avg_return(last100)=3.14\n",
      "[EP  3500] avg_return(last100)=2.35\n",
      "[EP  4000] avg_return(last100)=3.60\n",
      "[EP  4500] avg_return(last100)=2.42\n",
      "[EP  5000] avg_return(last100)=2.91\n",
      "Saved PNGs to: artifacts\\rl_taxi\\run_20251016-231608\\results_png\n",
      " - artifacts\\rl_taxi\\run_20251016-231608\\results_png\\alpha_0.2_confirm_curves.png\n"
     ]
    }
   ],
   "source": [
    "# Re-select best config and confirm with a fresh run\n",
    "best = summary_sorted.iloc[0]\n",
    "tag, a, e, g = best[\"tag\"], float(best[\"alpha\"]), float(best[\"epsilon\"]), float(best[\"gamma\"])\n",
    "print(f\"[BEST] {tag} | α={a} ε={e} γ={g} — confirming...\")\n",
    "\n",
    "confirm = qlearn_train(\n",
    "    env,\n",
    "    episodes=TRAIN[\"episodes\"],\n",
    "    alpha=a,\n",
    "    gamma=g,\n",
    "    epsilon_fn=(lambda ep, e=e: e),  # constant epsilon\n",
    "    max_steps=TRAIN[\"max_steps\"],\n",
    "    log_every=500,\n",
    ")\n",
    "\n",
    "# Make a visuals folder\n",
    "VISDIR = OUTDIR / \"results_png\"\n",
    "VISDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# (1) Learning curves (steps + returns + rolling mean)\n",
    "plot_run_curves(confirm, f\"{tag}_confirm\", outdir=VISDIR, show=False)\n",
    "\n",
    "print(\"Saved PNGs to:\", VISDIR)\n",
    "print(\" -\", VISDIR / f\"{tag}_confirm_curves.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2175095",
   "metadata": {},
   "source": [
    "### **Step 10 — Greedy Policy Wrapper**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ddfdb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedyPolicy:\n",
    "    \"\"\"\n",
    "    Wrapper compatible with utils.simulate_episodes():\n",
    "      - exposes select_action(state)\n",
    "      - supports optional epsilon for exploratory sims\n",
    "      - breaks ties randomly among max-Q actions\n",
    "    \"\"\"\n",
    "    def __init__(self, Q: np.ndarray, epsilon: float = 0.0, seed: int = 0):\n",
    "        self.Q = np.asarray(Q, dtype=float)\n",
    "        self.epsilon = float(epsilon)\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "\n",
    "    def select_action(self, state: int) -> int:\n",
    "        if self.epsilon > 0.0 and self.rng.random() < self.epsilon:\n",
    "            return int(self.rng.integers(self.Q.shape[1]))\n",
    "        row = self.Q[state]\n",
    "        best_idxs = np.flatnonzero(row == row.max())\n",
    "        return int(self.rng.choice(best_idxs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082db05e",
   "metadata": {},
   "source": [
    "**Overview:**\n",
    "- New name (GreedyPolicy) with same interface: select_action(state) for utils.simulate_episodes().\n",
    "- Adds random tie-breaking among max-Q actions to avoid bias.\n",
    "- Optional epsilon lets you run slightly exploratory evaluation sims (default 0.0 = purely greedy).\n",
    "- Uses a local RNG for reproducibility without affecting global state.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26a1bd9",
   "metadata": {},
   "source": [
    "### **Step 11 — Visual Simulation (human render) with GreedyPolicy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60ae5f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Episode 1 ---\n",
      "Start: taxi=(2,0), passenger=Yellow -> destination=Red\n",
      "Episode 1 finished: return=13, steps=8\n",
      "\n",
      "--- Episode 2 ---\n",
      "Start: taxi=(2,1), passenger=Yellow -> destination=Red\n",
      "Episode 2 finished: return=12, steps=9\n",
      "\n",
      "--- Episode 3 ---\n",
      "Start: taxi=(2,1), passenger=Yellow -> destination=Blue\n",
      "Episode 3 finished: return=9, steps=12\n",
      "\n",
      "--- Episode 4 ---\n",
      "Start: taxi=(0,3), passenger=Red -> destination=Green\n",
      "Episode 4 finished: return=4, steps=17\n",
      "\n",
      "--- Episode 5 ---\n",
      "Start: taxi=(1,4), passenger=Green -> destination=Blue\n",
      "Episode 5 finished: return=13, steps=8\n",
      "\n",
      "--- Episode 6 ---\n",
      "Start: taxi=(3,3), passenger=Red -> destination=Blue\n",
      "Episode 6 finished: return=6, steps=15\n",
      "\n",
      "--- Episode 7 ---\n",
      "Start: taxi=(2,0), passenger=Yellow -> destination=Green\n",
      "Episode 7 finished: return=9, steps=12\n",
      "\n",
      "--- Episode 8 ---\n",
      "Start: taxi=(3,1), passenger=Blue -> destination=Yellow\n",
      "Episode 8 finished: return=7, steps=14\n",
      "\n",
      "--- Episode 9 ---\n",
      "Start: taxi=(1,4), passenger=Green -> destination=Blue\n",
      "Episode 9 finished: return=13, steps=8\n",
      "\n",
      "--- Episode 10 ---\n",
      "Start: taxi=(4,4), passenger=Green -> destination=Yellow\n",
      "Episode 10 finished: return=7, steps=14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---- Viz settings ----\n",
    "SIM_EPISODES   = 10\n",
    "SIM_MAX_STEPS  = 200\n",
    "RENDER_DELAY_S = 0.05\n",
    "LOC_NAMES = [\"Red\", \"Green\", \"Yellow\", \"Blue\"]  # Taxi-v3 fixed map labels\n",
    "\n",
    "# Use the most recent trained Q (fallback to baseline if confirm doesn't exist)\n",
    "Q_src = confirm if 'confirm' in globals() else base_stats\n",
    "agent = GreedyPolicy(Q_src[\"Q\"], epsilon=0.0, seed=SEED + 999)\n",
    "\n",
    "# Human-render environment\n",
    "env_vis = gym.make(\"Taxi-v3\", render_mode=\"human\")\n",
    "\n",
    "for ep in range(1, SIM_EPISODES + 1):\n",
    "    state, info = env_vis.reset(seed=SEED + 50_000 + ep)  # fresh passenger/dest per episode\n",
    "    total_reward, done, t = 0, False, 0\n",
    "\n",
    "    # Episode header (decode for readability)\n",
    "    r, c, p, d = env_vis.unwrapped.decode(state)\n",
    "    p_str = \"in taxi\" if p == 4 else LOC_NAMES[p]\n",
    "    d_str = LOC_NAMES[d]\n",
    "    print(f\"--- Episode {ep} ---\")\n",
    "    print(f\"Start: taxi=({r},{c}), passenger={p_str} -> destination={d_str}\")\n",
    "\n",
    "    while not done and t < SIM_MAX_STEPS:\n",
    "        a = agent.select_action(state)\n",
    "        state, rwd, terminated, truncated, _ = env_vis.step(a)\n",
    "        done = terminated or truncated\n",
    "        total_reward += rwd\n",
    "        t += 1\n",
    "\n",
    "        # Render and small delay so it’s watchable\n",
    "        try: env_vis.render()\n",
    "        except Exception: pass\n",
    "        time.sleep(RENDER_DELAY_S)\n",
    "\n",
    "    print(f\"Episode {ep} finished: return={total_reward}, steps={t}\\n\")\n",
    "\n",
    "env_vis.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548a0267",
   "metadata": {},
   "source": [
    "**Overview:**\n",
    "\n",
    "- Uses GreedyPolicy(Q, ε=0) for purely greedy visualization.\n",
    "- Resets the env each episode with a new seed (varied passenger/destination) instead of manual state edits.\n",
    "- Decodes the starting state for a human-readable intro, then renders each step with a short delay.\n",
    "- Keeps the loop simple and distinct: no direct s-assignments, no tuple-length checks (Gymnasium returns 5-tuple).\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb998e17",
   "metadata": {},
   "source": [
    "### **Experimental Summary**\n",
    "\n",
    "We trained tabular Q-Learning on Taxi-v3 (500 states, 6 actions) with a baseline (α=0.10, ε=0.10, γ=0.90) and independent sweeps over α and ε.  \n",
    "Learning curves showed ↑ returns and ↓ steps/episode, indicating stable convergence.  \n",
    "**Best run:** `alpha_0.2` with **α=<0.2>**, **ε=<0.1>**, **γ=<0.9>** (selected by highest *last-100 avg return*).   \n",
    "Policy visuals confirm consistent, task-aligned action choices.  \n",
    "All figures saved as PNGs in `artifacts/rl_taxi/run_<timestamp>/results_png/`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl8020",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
